# Курс Байесовские методы анализа данных, ФТиАД 2018

### Где и когда
Занятия проходят по понедельникам, 18:00 — 21:00, ШАД, Оксфорд.

### Ссылки
Канал в telegram для объявлений: https://t.me/joinchat/AAAAAE-WyZ3yUXyJWQORLg

[Anytask курса](https://anytask.org/course/393) (если нет логина, зарегистрироваться. инвайт 6i8JY8t)

### Правила выставления оценок
В курсе предусмотрено несколько форм контроля знания:
* Домашние работы (на Python и теоретические)
* Экзамен

Итоговая оценка вычисляется на основе оценки за работу в семестре и оценки за экзамен:

O<sub>итоговая</sub> = 0.7 * О<sub>накопленная</sub> + 0.3 * О<sub>экз</sub>

O<sub>накопленная</sub> = О<sub>домашние задания</sub>

Оценка за домашнюю работу вычисляется как среднее по домашним заданиям.

Накопленная, экзаменационная и итоговая оценки округляются арифметически.

### Правила сдачи домашних заданий

Дедлайн по заданиям — начало следующего занятия (жесткий).

Два раза за курс дедлайн можно просрочить, в этом случае за каждый день просрочки будет начисляться штраф -1 балл.

При обнаружении плагиата оценки за домашнее задание обнуляются всем задействованным в списывании студентам.

### Материалы занятий
__Занятие 1. Байесовские рассуждения__
* [Видео лекции](https://www.youtube.com/playlist?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw)
* [Конспект лекции](https://drive.google.com/file/d/13Q58mRGh5uN8xyhMiTfoOXOYvxUKbvRY/view)
* [Еще один конспект](http://www.machinelearning.ru/wiki/images/8/8c/Lecture7_2012.pdf)
* [Задачи семинара](http://www.machinelearning.ru/wiki/images/1/18/S01_bayesian_reasoning_2016.pdf)

__Занятие 2. Сопряженные распределения и принцип наибольшей обоснованности__
* [Конспект-презентация](http://www.machinelearning.ru/wiki/images/b/bd/BMMO11_5.pdf)
* [Презентация с распределениями](https://github.com/ftad/BM2018/blob/master/materials/distributions.pdf)

__Занятие 3. Экспоненциальный класс распределений и матричное дифференцирование__
* [Конспект об экспоненциальном классе](https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter8.pdf) от Michael I. Jordan
* [Конспект о матричном дифференцировании и нормальном распределении](http://www.machinelearning.ru/wiki/images/6/6c/BMMO11_8.pdf)
* [О матричном дифференцировании](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) не очень доступно но полно
* [О матричном дифференцировании](http://www.machinelearning.ru/wiki/images/a/ab/MOMO18_Seminar1.pdf) не очень полно но доступно и с кучей примеров

__Занятие 4. Метод релевантных векторов__
* [Конспект-презентация](http://www.machinelearning.ru/wiki/images/d/d0/BMMO11_7.pdf)
* [Презентация с экспериментами](http://www.machinelearning.ru/wiki/images/8/8d/BMML15_S06_show.pdf)

__Занятие 5. EM-алгоритм__
* [Презентация по EM-алгоритму](https://drive.google.com/file/d/1CFGIuArumNz-qjVdCQqlxSpRbgGG3Ij_/view?usp=sharing)

__Занятие 6. EM-алгоритм. Решение задач__
* [Презентация по задаче с восстановлением фото](https://github.com/ftad/BM2018/blob/master/homeworks/homework6_theory.pdf)
* [Байесовский метод главных компонент](http://www.machinelearning.ru/wiki/images/7/73/BMMO11_11.pdf)

__Занятие 7. EM-алгоритм. Вариационный вывод__
* [Конспект с примерами применения](http://www.machinelearning.ru/wiki/images/3/34/Variational_inference.pdf)
* Теория с пояснениями - 21 chapter, Murphy K.P. Machine Learning: A Probabilistic Perspective.

__Занятие 8. Байесовские нейронные сети__
* [Презентация по байесовским нейронным сетям](https://drive.google.com/file/d/1yO2IQjYhx1R39ZSOSbJG7V0knwI_X7YC/view?usp=sharing)
* [Презентация по разреживающему вариационному дропауту](https://drive.google.com/file/d/1ZHy_26SOTpSLrYSfuBDF4khvrYlRmc-U/view?usp=sharing)
* Статьи: [VarDrop & LRT](https://arxiv.org/pdf/1506.02557.pdf), [ARD for NNs](https://arxiv.org/pdf/1811.00596.pdf), [SparseVD](https://arxiv.org/pdf/1701.05369.pdf), [BinDrop as BayesianNN](https://arxiv.org/pdf/1512.05287.pdf)

__Занятие 9. Вариационные автокодировщики__
* [Презентация](https://drive.google.com/file/d/1NqtMy7uMti9Xrsck9WIqvv8o3PWP1jS4/view?usp=sharing)

__Занятие 10. Методы Монте-Карло с марковскими цепями__
* [Конспект](http://www.machinelearning.ru/wiki/images/6/6b/BMMO11_10.pdf)
* [Подробный туториал на английском](https://www.cs.ubc.ca/~arnaud/andrieu_defreitas_doucet_jordan_intromontecarlomachinelearning.pdf)

__Занятие 11. Latent Dirichlet Allocation__

__Занятие 12. Гауссовские процессы__
* [Презентация Е. Бурнаева](https://drive.google.com/file/d/1yhSOkV2TNCSrjbrNMUtYerXXZY1dQpo4/view?usp=sharing)
* [Презентация М. Филиппоне](https://drive.google.com/file/d/0B2zoFVYw1rN3SDJ0OU1nNVRxVWc/view?usp=sharing)

### Задания
* [Домашнее задание 1](https://github.com/ftad/BM2018/blob/master/homeworks/homework1.pdf). Дедлайн: 18:00 17.09.18
* [Домашнее задание 2](https://github.com/ftad/BM2018/blob/master/homeworks/homework2.pdf). Дедлайн: 18:00 24.09.18. Сдавать в Anytask!
* [Домашнее задание 3](https://github.com/ftad/BM2018/blob/master/homeworks/homework3.pdf). Дедлайн: 18:00 01.10.18. Сдавать в Anytask!
* [Домашнее задание 4 (пр.)](https://github.com/ftad/BM2018/blob/master/homeworks/homework4.ipynb) Дедлайн: 18:00 08.10.18. Сдавать в Anytask! Обратите внимание, что в задании вектор правильных ответов обозначается t, а не y.

* [Домашнее задание 5](https://github.com/ftad/BM2018/blob/master/homeworks/homework5.pdf) Дедлайн: 18:00 29.10.18. Сдавать в Anytask!
* [Домашнее задание 6.](https://github.com/ftad/BM2018/blob/master/homeworks/homework6.ipynb) [Теория по заданию.](https://github.com/ftad/BM2018/blob/master/homeworks/homework6_theory.pdf) [Данные.](https://yadi.sk/d/EUF_qiKRpHo9cw) Дедлайн: 18:00 29.10.2018. Сдавать в Anytask!
* [Домашнее задание 7.](https://github.com/ftad/BM2018/blob/master/homeworks/homework7.pdf) Дедлайн: 18:00 07.11.2018. Сдавать в Anytask!
* [Домашнее задание 8.](https://github.com/ftad/BM2018/blob/master/homeworks/homework8.ipynb) Дедлайн: 23:59 20.11.2018.
* [Домашнее задание 9.](https://github.com/ftad/BM2018/blob/master/homeworks/homework9.pdf) Дедлайн: 18:00 11.12.18
* [Домашнее задание 10 (опциональное).](https://github.com/ftad/BM2018/blob/master/homeworks/homework10_opt.ipynb) Дедлайн: 23:59 23.12.18

### Полезные материалы
Книги:
* Barber D. [Bayesian Reasoning and Machine Learning.](http://www0.cs.ucl.ac.uk/staff/d.barber/brml/) Cambridge University Press, 2012.
* Murphy K.P. Machine Learning: A Probabilistic Perspective. The MIT Press, 2012.
* Bishop C.M. [Pattern Recognition and Machine Learning.](http://research.microsoft.com/en-us/um/people/cmbishop/prml/) Springer, 2006. 
* Mackay D.J.C. [Information Theory, Inference, and Learning Algorithms.](http://www.inference.phy.cam.ac.uk/mackay/itila/book.html) Cambridge University Press, 2003. 
* Tipping M. [Sparse Bayesian Learning.](http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf) Journal of Machine Learning Research, 1, 2001, pp. 211-244. 
* Шумский С.А. [Байесова регуляризация обучения.](http://www.niisi.ru/iont/ni/Library/School-2002/Shumsky-2002.pdf) В сб. Лекции по нейроинформатике, часть 2, 2002.

Простые и удобные [заметки](http://cs.nyu.edu/~roweis/notes.html) по матричным вычислениям и свойствам гауссовских распределений.

[Памятка](http://statistics.zone/) по теории вероятностей.
